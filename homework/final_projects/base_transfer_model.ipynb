{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дообучение готовой архитектуры НС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка дополнительных библиотек для работы с НС\n",
    "!pip install -q kaggle torch torchvision torchmetrics ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = './'\n",
    "SPLIT_DATA_DIR = ROOT_DIR + 'data_prepared/'\n",
    "\n",
    "TRAIN_DATA_DIR = SPLIT_DATA_DIR + 'train/'\n",
    "VALID_DATA_DIR = SPLIT_DATA_DIR + 'valid/'\n",
    "TEST_DATA_DIR = SPLIT_DATA_DIR + 'test/'\n",
    "\n",
    "# TEST_DATA_FAKE_LABEL_COPY_DIR = TEST_DATA_COPY_DIR + 'all_classes/'\n",
    "# SHORT_TRAIN_DATA_COPY_DIR = DATA_COPY_DIR + 'short_train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим разбиение на train и valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(\n",
    "    num_val_images_per_class,\n",
    "    num_test_images_per_class\n",
    "):\n",
    "    \"\"\"Функция разбивает датасет из дериктории train на valid и test\"\"\"\n",
    "    os.makedirs(VALID_DATA_DIR, exist_ok = True)\n",
    "\n",
    "    classes = os.listdir(TRAIN_DATA_DIR)\n",
    "\n",
    "    for class_name in classes:\n",
    "\n",
    "        list_of_pics = os.listdir(TRAIN_DATA_DIR + class_name)\n",
    "\n",
    "        os.mkdir(VALID_DATA_DIR + class_name)\n",
    "\n",
    "        val_list_of_pics = np.random.choice(list_of_pics, size = num_val_images_per_class, replace=False)\n",
    "\n",
    "        for pic in val_list_of_pics:\n",
    "            shutil.move(TRAIN_DATA_DIR + class_name + '/' + pic, VALID_DATA_DIR + class_name + '/' + pic)\n",
    "            \n",
    "    os.makedirs(TEST_DATA_DIR, exist_ok = True)\n",
    "\n",
    "    for class_name in classes:\n",
    "\n",
    "        list_of_pics = os.listdir(TRAIN_DATA_DIR + class_name)\n",
    "\n",
    "        os.mkdir(TEST_DATA_DIR + class_name)\n",
    "\n",
    "        val_list_of_pics = np.random.choice(list_of_pics, size = num_val_images_per_class, replace=False)\n",
    "\n",
    "        for pic in val_list_of_pics:\n",
    "            shutil.move(TRAIN_DATA_DIR + class_name + '/' + pic, TEST_DATA_DIR + class_name + '/' + pic)\n",
    "            \n",
    "if not os.path.isdir(VALID_DATA_DIR):\n",
    "    train_valid_split(100, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим даталоадеры. Добавте в transform аугментацию.\n",
    "\n",
    "Например, следующими функциями (где нужно)\n",
    "- transforms.Normalize\n",
    "- transforms.RandomHorizontalFlip\n",
    "- transforms.RandomResizedCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform_train = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "transform_valid = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DATA_DIR, transform=transform_train)\n",
    "valid_dataset = datasets.ImageFolder(VALID_DATA_DIR, transform=transform_valid)\n",
    "test_dataset = datasets.ImageFolder(TEST_DATA_DIR, transform = transform_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 1,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектура модели\n",
    "\n",
    "Для примера посмотрим на классический AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18 = models.resnet18(pretrained=True)\n",
    "print(resnet18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pretrainde_RESNET18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        pretrained_net = models.resnet18(pretrained=True)\n",
    "\n",
    "        self.features = torch.nn.Sequential(*(list(pretrained_net.children())[:-1]))\n",
    "\n",
    "        self.classifier = torch.nn.Sequential(\n",
    "            nn.Linear(in_features=512, out_features=300),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=300, out_features=200)\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.classifier[0].weight)\n",
    "        nn.init.kaiming_normal_(self.classifier[2].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        features = nn.Flatten(start_dim = 1)(features)\n",
    "        logits = self.classifier(features)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы:\n",
    "* что значит параметр pretrained=True? (опишите как можно больше деталей)\n",
    "* что делает следующая строчка nn.init.kaiming_normal_?  Какую проблему мы хотим решить?\n",
    "* Опишите как работает dropout. Какие есть отличия при обучении и при применении модели?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Процесс обучения\n",
    "\n",
    "В классе реализованно итерирование по эпохам и бачам (через даталоадер)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_training():\n",
    "\n",
    "    def __init__(self, lr, trainloader, testloader, device, model):\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "        self.device = device\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.opt = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr = lr,\n",
    "            weight_decay = 0.0001\n",
    "        )\n",
    "\n",
    "        self.best_model = None\n",
    "        self.best_epoch = None\n",
    "\n",
    "        self.loss_train = []\n",
    "        self.loss_test = []\n",
    "        self.metric_train = []\n",
    "        self.metric_test = []\n",
    "\n",
    "    def accuracy(self, y_predicts, y_labels):\n",
    "        acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
    "        return acc\n",
    "\n",
    "    def train_nn(self, trainloader, model, opt, loss_fn, device):\n",
    "        \"\"\"Функция итерирование по бачам для обучения\"\"\"\n",
    "        model.train()\n",
    "        running_loss_train = []\n",
    "        running_acc_train = []\n",
    "\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs).to(device)\n",
    "            y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
    "\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            running_loss_train.append(loss.item())\n",
    "            running_acc_train.append(self.accuracy(y_pred, labels))\n",
    "            \n",
    "        return model, running_loss_train, running_acc_train\n",
    "\n",
    "    def eval_nn(self, testloader, model, loss_fn, device):\n",
    "        \"\"\"Функция итерирование по бачам для валидации\"\"\"\n",
    "        model.eval()\n",
    "        running_loss_test = []\n",
    "        running_acc_test = []\n",
    "        \n",
    "        for batch in tqdm(valid_dataloader):\n",
    "\n",
    "            inputs, labels = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs).to(device)\n",
    "            y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            running_loss_test.append(loss.item())\n",
    "            running_acc_test.append(self.accuracy(y_pred, labels))\n",
    "\n",
    "        return running_loss_test, running_acc_test\n",
    "\n",
    "    def training_loop(self, max_epochs = 10):\n",
    "        \"\"\"Функция обучения по эпохам\"\"\"\n",
    "        print('Начинаю обучение')\n",
    "        start_training_time = time.time()\n",
    "\n",
    "        for epoch in tqdm(range(max_epochs)):\n",
    "\n",
    "            start_epoch_time = time.time()\n",
    "\n",
    "            self.model, running_loss_train, running_acc_train = self.train_nn(\n",
    "                self.trainloader,\n",
    "                self.model,\n",
    "                self.opt,\n",
    "                self.loss_fn,\n",
    "                self.device\n",
    "            )\n",
    "\n",
    "            running_loss_test, running_acc_test = self.eval_nn(\n",
    "                self.testloader,\n",
    "                self.model,\n",
    "                self.loss_fn,\n",
    "                self.device\n",
    "            )\n",
    "\n",
    "            self.loss_train.append(np.mean(running_loss_train))\n",
    "            self.loss_test.append(np.mean(running_loss_test))\n",
    "\n",
    "            self.metric_train.append(np.mean(running_acc_train))\n",
    "            self.metric_test.append(np.mean(running_acc_test))\n",
    "\n",
    "            if np.mean(running_acc_test) >= np.max(self.metric_test):\n",
    "                self.best_model = deepcopy(self.model)\n",
    "                self.best_epoch = epoch\n",
    "                torch.save(main_loop.best_model, './models/custom_transfer_model.pt')\n",
    "\n",
    "            duration_epoch = time.time() - start_epoch_time\n",
    "\n",
    "            print(f\"\"\"EPOCH {epoch} :\n",
    "            train_loss: {self.loss_train[-1]:.5f}\n",
    "            test_loss: {self.loss_test[-1]:.5f}\n",
    "            train_acc: {self.metric_train[-1]:.5f}\n",
    "            test_acc: {self.metric_test[-1]:.5f}\n",
    "            Эпоха заняла по времени {round(duration_epoch / 60, 2)} минут\"\"\")\n",
    "\n",
    "        duration_total = time.time() - start_training_time\n",
    "        print(f'Всего обучение заняло: {round(duration_total / 60, 2)} минут')\n",
    "        print(f'Лучшее значение метрики было достингнуто на {self.best_epoch} эпохе')\n",
    "\n",
    "        fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize=(10, 8))\n",
    "\n",
    "        axes[0, 0].plot(range(max_epochs), self.loss_train)\n",
    "        axes[0, 0].set_title('loss_train')\n",
    "\n",
    "        axes[0, 1].plot(range(max_epochs), self.loss_test)\n",
    "        axes[0, 1].set_title('loss_test')\n",
    "\n",
    "        axes[1, 0].plot(range(max_epochs), self.metric_train)\n",
    "        axes[1, 0].set_title('metric_train')\n",
    "\n",
    "        axes[1, 1].plot(range(max_epochs), self.metric_test)\n",
    "        axes[1, 1].set_title('metric_test')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pretrainde_RESNET18()\n",
    "model.features.requires_grad_ = False\n",
    "model.to(DEVICE)\n",
    "\n",
    "main_loop = model_training(0.01, train_dataloader, valid_dataloader, DEVICE, model)\n",
    "main_loop.training_loop(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы:\n",
    "* Что делает эта строчка и зачем model.features.requires_grad_ = False? Можем ли мы учить модель без этого флага? Если да то когда\n",
    "* почему Learning_rate ставится низким? Почему нельзя указывать большие значения?\n",
    "* в чем разница в работе модели в model.eval()  и model.train ()?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка качества на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = torch.load('./models/custom_transfer_model.pt')\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(y_predicts, y_labels):\n",
    "    acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
    "    return acc\n",
    "\n",
    "best_model.eval()\n",
    "running_loss_test = []\n",
    "running_acc_test = []\n",
    "        \n",
    "for batch in tqdm(valid_dataloader):\n",
    "\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    outputs = best_model(inputs).to(DEVICE)\n",
    "    y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(DEVICE)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "\n",
    "    running_loss_test.append(loss.item())\n",
    "    running_acc_test.append(accuracy(y_pred, labels))\n",
    "    \n",
    "    \n",
    "print(np.mean(running_loss_test))\n",
    "print(np.mean(running_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка и отправка на kaggle\n",
    "Проскорте полученной моделью "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c hse-summer-2023-cnn -f <ваши прогнозы>.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
