{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Собственная архитектура НС"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# установка дополнительных библиотек для работы с НС\n",
    "!pip install -q kaggle torch torchvision torchmetrics ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import deepcopy\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = './'\n",
    "SPLIT_DATA_DIR = ROOT_DIR + 'data_prepared/'\n",
    "\n",
    "TRAIN_DATA_DIR = SPLIT_DATA_DIR + 'train/'\n",
    "VALID_DATA_DIR = SPLIT_DATA_DIR + 'valid/'\n",
    "TEST_DATA_DIR = SPLIT_DATA_DIR + 'test/'\n",
    "\n",
    "# TEST_DATA_FAKE_LABEL_COPY_DIR = TEST_DATA_COPY_DIR + 'all_classes/'\n",
    "# SHORT_TRAIN_DATA_COPY_DIR = DATA_COPY_DIR + 'short_train/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим разбиение на train и valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_split(\n",
    "    num_val_images_per_class,\n",
    "    num_test_images_per_class\n",
    "):\n",
    "\n",
    "    os.makedirs(VALID_DATA_DIR, exist_ok = True)\n",
    "\n",
    "    classes = os.listdir(TRAIN_DATA_DIR)\n",
    "\n",
    "    for class_name in classes:\n",
    "\n",
    "        list_of_pics = os.listdir(TRAIN_DATA_DIR + class_name)\n",
    "\n",
    "        os.mkdir(VALID_DATA_DIR + class_name)\n",
    "\n",
    "        val_list_of_pics = np.random.choice(list_of_pics, size = num_val_images_per_class, replace=False)\n",
    "\n",
    "        for pic in val_list_of_pics:\n",
    "            shutil.move(TRAIN_DATA_DIR + class_name + '/' + pic, VALID_DATA_DIR + class_name + '/' + pic)\n",
    "            \n",
    "    os.makedirs(TEST_DATA_DIR, exist_ok = True)\n",
    "\n",
    "    for class_name in classes:\n",
    "\n",
    "        list_of_pics = os.listdir(TRAIN_DATA_DIR + class_name)\n",
    "\n",
    "        os.mkdir(TEST_DATA_DIR + class_name)\n",
    "\n",
    "        val_list_of_pics = np.random.choice(list_of_pics, size = num_val_images_per_class, replace=False)\n",
    "\n",
    "        for pic in val_list_of_pics:\n",
    "            shutil.move(TRAIN_DATA_DIR + class_name + '/' + pic, TEST_DATA_DIR + class_name + '/' + pic)\n",
    "            \n",
    "if not os.path.isdir(VALID_DATA_DIR):\n",
    "    train_valid_split(100, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим даталоадеры. Добавте в transform аугментацию.\n",
    "\n",
    "Например, следующими функциями (где нужно)\n",
    "- transforms.Normalize\n",
    "- transforms.RandomHorizontalFlip\n",
    "- transforms.RandomResizedCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "transform_train = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "transform_valid = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(TRAIN_DATA_DIR, transform=transform_train)\n",
    "valid_dataset = datasets.ImageFolder(VALID_DATA_DIR, transform=transform_valid)\n",
    "test_dataset = datasets.ImageFolder(TEST_DATA_DIR, transform = transform_test)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "valid_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 1,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Архитектура модели\n",
    "\n",
    "Сначала собираем и учим автоэнкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        def initialization(layer):\n",
    "            if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.ConvTranspose2d):\n",
    "                nn.init.kaiming_normal_(layer.weight)\n",
    "                layer.bias.data.fill_(0.)\n",
    "\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(3, 128, kernel_size=(3, 3), padding = 1, stride = 1),\n",
    "                                     nn.ELU(),\n",
    "                                     nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "                                     nn.Conv2d(128, 64, kernel_size=(3, 3), padding = 1, stride = 1),\n",
    "                                     nn.ELU(),\n",
    "                                     nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "                                     nn.Conv2d(64, 32, kernel_size=(3, 3), padding = 1, stride = 1),\n",
    "                                     nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(nn.ConvTranspose2d(32, 64, kernel_size=(3, 3),\n",
    "                                                        padding = 1, stride = 1),\n",
    "                                     nn.ELU(),\n",
    "                                     nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                                     nn.ConvTranspose2d(64, 128, kernel_size=(3, 3), \n",
    "                                                        padding = 1, stride = 1),\n",
    "                                     nn.ELU(),\n",
    "                                     nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                                     nn.ConvTranspose2d(128, 3, kernel_size=(3, 3), \n",
    "                                                        padding = 1, stride = 1),\n",
    "                                     nn.ELU()\n",
    "        )\n",
    "\n",
    "        self.apply(initialization)\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent_code = self.encoder(x)\n",
    "        reconstruction = self.decoder(latent_code)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_train, y_train in  train_dataloader:\n",
    "    break\n",
    "    \n",
    "for x_valid, y_valid in  valid_dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoEncoder()\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0003)\n",
    "                      \n",
    "def run_train(model, criterion, optimizer, x_train, x_valid):\n",
    "    for epoch in range(50):\n",
    "        print(f'epoch: {epoch}')\n",
    "        \n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_train) \n",
    "        loss = criterion(output, x_train)\n",
    "        loss.backward()\n",
    "        print(f'loss_train: {loss.item()}')\n",
    "        optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        output = model(x_valid)\n",
    "        loss = criterion(output, x_valid)\n",
    "        print(f'loss_valid: {loss.item()}')\n",
    "\n",
    "run_train(model, criterion, optimizer, x_train, x_valid) # переобучение на одном батче\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы:\n",
    "* Зачем делать шаг переобучения на одном батче? \n",
    "* Мы используем MSE лосс - что это? Какие лоссы вы еще знаете для задачи регрессии? Опишите их применимость и особенности\n",
    "* А что произойдет, если мы заменим лосс на бинарный (например на бинарную кросс энтропию)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullModel(nn.Module):\n",
    "    def __init__(self,ae_model, num_classes: int = 200) -> None:\n",
    "        super(FullModel, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            ae_model.encoder\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d((3, 3))\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32 * 5 * 5, 2024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2024, 2024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2024, num_classes),\n",
    "        )\n",
    "\n",
    "    def _forward_impl(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Вопрос:\n",
    " *  Как понять входную размерность слоя в classifier? (32 * 5 * 5 что значат эти цифры?)\n",
    " * Какую задачу пытается решить autoencoder? \n",
    " * Опишите разницу между max_pool и avg_pool. Как вы думаете когда стоит использовать avg_pool, а когда max_pool?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Процесс обучения\n",
    "\n",
    "В классе реализованно итерирование по эпохам и бачам (через даталоадер)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_training():\n",
    "\n",
    "    def __init__(self, lr, train_autoencode, trainloader, testloader, device, model):\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "        self.device = device\n",
    "        self.train_autoencode = train_autoencode\n",
    "        \n",
    "        self.model = model\n",
    "        if train_autoencode:\n",
    "            self.loss_fn = torch.nn.MSELoss()\n",
    "        else:\n",
    "            self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            \n",
    "        \n",
    "        \n",
    "        # добвляем возможность выбирать лосс, чтобы учить в одном классе обе модели\n",
    "        \n",
    "        self.opt = optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr = lr,\n",
    "            weight_decay = 0.0001\n",
    "        )\n",
    "\n",
    "        self.best_model = None\n",
    "        self.best_epoch = None\n",
    "\n",
    "        self.loss_train = []\n",
    "        self.loss_test = []\n",
    "        self.metric_train = []\n",
    "        self.metric_test = []\n",
    "\n",
    "    def accuracy(self, y_predicts, y_labels):\n",
    "        acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
    "        return acc\n",
    "\n",
    "    def train_nn(self, trainloader, model, opt, loss_fn, device):\n",
    "        \"\"\"Функция итерирование по бачам для обучения\"\"\"\n",
    "        model.train()\n",
    "        running_loss_train = []\n",
    "        running_acc_train = []\n",
    "        if self.train_autoencode:\n",
    "            for batch in tqdm(train_dataloader):\n",
    "                inputs, labels = batch\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                outputs = model(inputs).to(device)\n",
    "                \n",
    "\n",
    "                loss = loss_fn(outputs, inputs)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                running_loss_train.append(loss.item())\n",
    "                running_acc_train.append(loss.item())\n",
    "        else:\n",
    "            for batch in tqdm(train_dataloader):\n",
    "                inputs, labels = batch\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                opt.zero_grad()\n",
    "                outputs = model(inputs).to(device)\n",
    "                y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
    "\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "\n",
    "                running_loss_train.append(loss.item())\n",
    "                running_acc_train.append(self.accuracy(y_pred, labels))\n",
    "            \n",
    "\n",
    " \n",
    "            \n",
    "        return model, running_loss_train, running_acc_train\n",
    "\n",
    "    def eval_nn(self, testloader, model, loss_fn, device):\n",
    "        \"\"\"Функция итерирование по бачам для валидации\"\"\"\n",
    "        model.eval()\n",
    "        running_loss_test = []\n",
    "        running_acc_test = []\n",
    "        if self.train_autoencode:\n",
    "            for batch in tqdm(valid_dataloader):\n",
    "                inputs, labels = batch\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                outputs = model(inputs).to(device)\n",
    "                loss = loss_fn(outputs, inputs)\n",
    "\n",
    "                running_loss_test.append(loss.item())\n",
    "                running_acc_test.append(loss.item())\n",
    "        else:\n",
    "            \n",
    "        \n",
    "            for batch in tqdm(valid_dataloader):\n",
    "\n",
    "                inputs, labels = batch\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs).to(device)\n",
    "                y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(device)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                running_loss_test.append(loss.item())\n",
    "                running_acc_test.append(self.accuracy(y_pred, labels))\n",
    "\n",
    "        return running_loss_test, running_acc_test\n",
    "\n",
    "    def training_loop(self, max_epochs = 10):\n",
    "        \"\"\"Функция обучения по эпохам\"\"\"\n",
    "        print('Начинаю обучение')\n",
    "        start_training_time = time.time()\n",
    "\n",
    "        for epoch in tqdm(range(max_epochs)):\n",
    "\n",
    "            start_epoch_time = time.time()\n",
    "\n",
    "            self.model, running_loss_train, running_acc_train = self.train_nn(\n",
    "                self.trainloader,\n",
    "                self.model,\n",
    "                self.opt,\n",
    "                self.loss_fn,\n",
    "                self.device\n",
    "            )\n",
    "\n",
    "            running_loss_test, running_acc_test = self.eval_nn(\n",
    "                self.testloader,\n",
    "                self.model,\n",
    "                self.loss_fn,\n",
    "                self.device\n",
    "            )\n",
    "\n",
    "            self.loss_train.append(np.mean(running_loss_train))\n",
    "            self.loss_test.append(np.mean(running_loss_test))\n",
    "\n",
    "            self.metric_train.append(np.mean(running_acc_train))\n",
    "            self.metric_test.append(np.mean(running_acc_test))\n",
    "\n",
    "            if np.mean(running_acc_test) >= np.max(self.metric_test):\n",
    "                self.best_model = deepcopy(self.model)\n",
    "                self.best_epoch = epoch\n",
    "                torch.save(main_loop.best_model, './models/custom_model.pt')\n",
    "\n",
    "            duration_epoch = time.time() - start_epoch_time\n",
    "\n",
    "            print(f\"\"\"EPOCH {epoch} :\n",
    "            train_loss: {self.loss_train[-1]:.5f}\n",
    "            test_loss: {self.loss_test[-1]:.5f}\n",
    "            train_acc: {self.metric_train[-1]:.5f}\n",
    "            test_acc: {self.metric_test[-1]:.5f}\n",
    "            Эпоха заняла по времени {round(duration_epoch / 60, 2)} минут\"\"\")\n",
    "\n",
    "        duration_total = time.time() - start_training_time\n",
    "        print(f'Всего обучение заняло: {round(duration_total / 60, 2)} минут')\n",
    "        print(f'Лучшее значение метрики было достингнуто на {self.best_epoch} эпохе')\n",
    "\n",
    "        fig, axes = plt.subplots(nrows = 2, ncols = 2, figsize=(10, 8))\n",
    "\n",
    "        axes[0, 0].plot(range(max_epochs), self.loss_train)\n",
    "        axes[0, 0].set_title('loss_train')\n",
    "\n",
    "        axes[0, 1].plot(range(max_epochs), self.loss_test)\n",
    "        axes[0, 1].set_title('loss_test')\n",
    "\n",
    "        axes[1, 0].plot(range(max_epochs), self.metric_train)\n",
    "        axes[1, 0].set_title('metric_train')\n",
    "\n",
    "        axes[1, 1].plot(range(max_epochs), self.metric_test)\n",
    "        axes[1, 1].set_title('metric_test')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_ae = AutoEncoder()\n",
    "model_ae.to(DEVICE)\n",
    "train_autoencode = True\n",
    "\n",
    "main_loop_ae = model_training(0.01,train_autoencode, train_dataloader, valid_dataloader, DEVICE, model_ae)\n",
    "main_loop_ae.training_loop(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FullModel(model_ae)\n",
    "model.features.requires_grad_ = False\n",
    "model.to(DEVICE)\n",
    "train_autoencode = False\n",
    "main_loop = model_training(0.01, train_autoencode, \n",
    "                           train_dataloader, \n",
    "                           valid_dataloader, \n",
    "                           DEVICE, model)\n",
    "main_loop.training_loop(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Вопрос:\n",
    " * Опишите разницу применения автоэнкодера и трансферлернинга. Когда автоэнкодер предпочтительнее?\n",
    " * Возможно ли переобучение когда мы обучаем автоэкодер? Надо ли снижать уровень регуляризации при построении (относительно обычной модели)\n",
    " * Что такое латентное пространство в автоэнкодере? Может ли оно быть больше чем исходная размерность объектов?\n",
    " * Можно ли строить автоэнкодеры для текстов?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка качества на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e71f4c246014bf49ff4826823e5559e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.301841595683235\n",
      "0.0049920127795527154\n"
     ]
    }
   ],
   "source": [
    "best_model = torch.load('./models/custom_model.pt')\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy(y_predicts, y_labels):\n",
    "    acc = (y_predicts == y_labels).sum().item() / y_predicts.size(0)\n",
    "    return acc\n",
    "\n",
    "best_model.eval()\n",
    "running_loss_test = []\n",
    "running_acc_test = []\n",
    "        \n",
    "for batch in tqdm(valid_dataloader):\n",
    "\n",
    "    inputs, labels = batch\n",
    "    inputs = inputs.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "\n",
    "    outputs = best_model(inputs).to(DEVICE)\n",
    "    y_pred = nn.Softmax(dim=1)(outputs).argmax(dim=1).to(DEVICE)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "\n",
    "    running_loss_test.append(loss.item())\n",
    "    running_acc_test.append(accuracy(y_pred, labels))\n",
    "    \n",
    "    \n",
    "print(np.mean(running_loss_test))\n",
    "print(np.mean(running_acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка и отправка на kaggle\n",
    "Проскорте полученной моделью данные для сабмита и отправьте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !kaggle competitions submit -c hse-summer-2023-cnn -f <ваши прогнозы>.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
